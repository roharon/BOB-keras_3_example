{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense, Conv1D, MaxPool2D, Flatten, Embedding\n",
    "from keras.layers import Dropout, Flatten, GlobalMaxPool1D, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imdb데이터셋을 사용하기전 전처리가 필요하다.\n",
    "Keras의 전처리 함수인 pad_sequences를 사용 \n",
    "imdb에서 불러올 크기는 10000 으로 지정했다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_label, y_label) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_label = sequence.pad_sequences(x_label, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과가 이진으로 나뉘어지는 문제다. 따라서 Dense이후에 sigmoid를 붙여 최종적인 결과를 낸다.\n",
    " \n",
    "레이어를 선형으로 쌓기위해 Sequential 모델을 만든다.\n",
    "Embedding에서의 첫번째 파라미터는 input_dim이다. 이는 imdb load시의 크기와 같아야하므로\n",
    "max_features로 둔다. 두번째 인자는 output_dim으로, 50차원 공간에 두는 것이다.\n",
    "input_length로 maxlen인 500을 두었으며 문장길이를 지정하였다.\n",
    "Dropout은 과적합 방지를 위해 사용하였다. 입력데이터 * 0.2만큼 입력값으로 사용하지 않는다.\n",
    "GlobalMaxPool1d 를 사용하였는데 이는 3차원을 2차원으로 변형해준다.\n",
    "\n",
    "Dense로 출력뉴런의 수를 1로 정한다. 입력뉴런은 GlobalMaxPool1d에서 나온 2이다\n",
    "은닉층에 relu레이어를 둔다..\n",
    "이 문제는 **positive negative를 판별하는 문제기에** 마지막으로 sigmoid함수를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 50, input_length=maxlen))\n",
    "# 50dimension\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(250, 3,\n",
    "                padding='valid',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼포먼스를 위해 옵티마이저로 rmsprop를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 11:47:18.364218 140120434202432 deprecation_wrapper.py:119] From /home/aaronroh/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0803 11:47:18.394880 140120434202432 deprecation_wrapper.py:119] From /home/aaronroh/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0803 11:47:18.399853 140120434202432 deprecation.py:323] From /home/aaronroh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 가지고 훈련을 하는데 epoch는 25, 훈련은 0.8, 검증데이터셋은 0.2로 나누어 진행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.5295 - acc: 0.7166 - val_loss: 0.3544 - val_acc: 0.8464\n",
      "Epoch 2/25\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.3090 - acc: 0.8683 - val_loss: 0.2813 - val_acc: 0.8822\n",
      "Epoch 3/25\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2353 - acc: 0.9053 - val_loss: 0.2599 - val_acc: 0.8956\n",
      "Epoch 4/25\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.1835 - acc: 0.9303 - val_loss: 0.2821 - val_acc: 0.8888\n",
      "Epoch 5/25\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.1512 - acc: 0.9439 - val_loss: 0.2637 - val_acc: 0.8986\n",
      "Epoch 6/25\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1197 - acc: 0.9561 - val_loss: 0.3584 - val_acc: 0.8720\n",
      "Epoch 7/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0944 - acc: 0.9652 - val_loss: 0.3113 - val_acc: 0.8906\n",
      "Epoch 8/25\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0701 - acc: 0.9766 - val_loss: 0.3195 - val_acc: 0.8962\n",
      "Epoch 9/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0530 - acc: 0.9824 - val_loss: 0.6051 - val_acc: 0.8316\n",
      "Epoch 10/25\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0380 - acc: 0.9876 - val_loss: 0.3769 - val_acc: 0.8956\n",
      "Epoch 11/25\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.3947 - val_acc: 0.8978\n",
      "Epoch 12/25\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0183 - acc: 0.9944 - val_loss: 0.5006 - val_acc: 0.8820\n",
      "Epoch 13/25\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0144 - acc: 0.9952 - val_loss: 0.4588 - val_acc: 0.8998\n",
      "Epoch 14/25\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.5121 - val_acc: 0.8936\n",
      "Epoch 15/25\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0076 - acc: 0.9972 - val_loss: 0.5386 - val_acc: 0.8966\n",
      "Epoch 16/25\n",
      "20000/20000 [==============================] - 36s 2ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.5806 - val_acc: 0.8924\n",
      "Epoch 17/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.5931 - val_acc: 0.8928\n",
      "Epoch 18/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.6256 - val_acc: 0.8936\n",
      "Epoch 19/25\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.6407 - val_acc: 0.8932\n",
      "Epoch 20/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.7768 - val_acc: 0.8800\n",
      "Epoch 21/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.7232 - val_acc: 0.8934\n",
      "Epoch 22/25\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.7218 - val_acc: 0.8924\n",
      "Epoch 23/25\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 0.8107 - val_acc: 0.8894\n",
      "Epoch 24/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.8146 - val_acc: 0.8868\n",
      "Epoch 25/25\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.7558 - val_acc: 0.8926\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=25,\n",
    "                   batch_size = 128,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 모델에 대한 요약이다.\n",
    "레이어는 embedding-dropout-conv1d-global_max_pooling1d - dense - dropout - activation - dense - activation 로 구성되어있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 50)           500000    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 498, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 600,751\n",
      "Trainable params: 600,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도는 0.88296이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 8s 333us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8321108200644143, 0.88296]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_label, y_label)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
